{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b53fc13",
   "metadata": {},
   "source": [
    "# Data Cleaning And Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097923f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09b6edf0",
   "metadata": {},
   "source": [
    "## Cleaning STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e78016",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Reading a CSV file\n",
    "import pandas as pd\n",
    "df = pd.read_csv('filename.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Checking the shape of the DataFrame\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Checking the data types of the columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25525cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Checking the number of missing values in each column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Dropping columns\n",
    "df.drop(['column1', 'column2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc03f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Renaming columns\n",
    "df.rename(columns={'old_name': 'new_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e9a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Changing the data type of a column:\n",
    "df['column'] = df['column'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27794f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "8A. Handling missing data (dropping rows with missing values):\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "8B. Handling missing data (imputing missing values with the median)\n",
    "df.fillna(df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e054cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "8C. Handling missing data (imputing missing values with the mean)\n",
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08243bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "8D. Handling missing data (imputing missing values with a constant)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Handling Outliers\n",
    "\n",
    "# Box Plot\n",
    "import seaborn as sns\n",
    "sns.boxplot(df_diabetics['bmi'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e5c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "9B:   Z-score\n",
    "\n",
    "import numpy as np\n",
    "outliers = []\n",
    "def detect_outliers_zscore(data):\n",
    "    thres = 3\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    # print(mean, std)\n",
    "    for i in data:\n",
    "        z_score = (i-mean)/std\n",
    "        if (np.abs(z_score) > thres):\n",
    "            outliers.append(i)\n",
    "    return outliers# \n",
    "sample_outliers = detect_outliers_zscore(sample)\n",
    "for i in sample_outliers:\n",
    "    a = np.delete(sample, np.where(sample==i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03567be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "9C. Inter Quantile Range(IQR)\n",
    "\n",
    "outliers = []\n",
    "def detect_outliers_iqr(data):\n",
    "    data = sorted(data)\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    # print(q1, q3)\n",
    "    IQR = q3-q1\n",
    "    lwr_bound = q1-(1.5*IQR)\n",
    "    upr_bound = q3+(1.5*IQR)\n",
    "    # print(lwr_bound, upr_bound)\n",
    "    for i in data: \n",
    "        if (i<lwr_bound or i>upr_bound):\n",
    "            outliers.append(i)\n",
    "    return outliers# Driver code\n",
    "sample_outliers = detect_outliers_iqr(sample)\n",
    "for i in sample_outliers:\n",
    "    a = np.delete(sample, np.where(sample==i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b95b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Detection '''\n",
    "# IQR\n",
    "# Calculate the upper and lower limits\n",
    "Q1 = df_diabetes['bmi'].quantile(0.25)\n",
    "Q3 = df_diabetes['bmi'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5*IQR\n",
    "upper = Q3 + 1.5*IQR\n",
    " \n",
    "# Create arrays of Boolean values indicating the outlier rows\n",
    "upper_array = np.where(df_diabetes['bmi']>=upper)[0]\n",
    "lower_array = np.where(df_diabetes['bmi']<=lower)[0]\n",
    " \n",
    "# Removing the outliers\n",
    "df_diabetes.drop(index=upper_array, inplace=True)\n",
    "df_diabetes.drop(index=lower_array, inplace=True)\n",
    " \n",
    "# Print the new shape of the DataFrame\n",
    "print(\"New Shape: \", df_diabetes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b7d8bf",
   "metadata": {},
   "source": [
    "## Feature Preprocessing and transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6896da64",
   "metadata": {},
   "source": [
    "## Dealing with categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a240d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "12. Handling categorical data (creating dummy variables)\n",
    "df = pd.get_dummies(df, columns=['categorical_column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f6723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd0760",
   "metadata": {},
   "outputs": [],
   "source": [
    "13. Handling categorical data (label encoding)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['encoded_column'] = encoder.fit_transform(df['categorical_column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3cd810",
   "metadata": {},
   "outputs": [],
   "source": [
    "14. Handling numerical data (binning)\n",
    "df['binned_column'] = pd.cut(\n",
    "df['numerical_column'], \n",
    "bins=5, \n",
    "labels=['very_low', 'low', 'medium', 'high', 'very_high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "15. Handling numerical data (scaling to a range)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df['scaled_column'] = scaler.fit_transform(df[['numerical_column']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "16. Handling numerical data (standardization)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df['standardized_column'] = scaler.fit_transform(df[['numerical_column']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "17. Handling datetime data (converting to datetime format)\n",
    "df['datetime_column'] = pd.to_datetime(df['datetime_column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "18. Handling datetime data (extracting year)\n",
    "df['year'] = df['datetime_column'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda75279",
   "metadata": {},
   "outputs": [],
   "source": [
    "19. Handling datetime data (extracting month)\n",
    "df['month'] = df['datetime_column'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dad76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "20. Handling datetime data (extracting day)\n",
    "df['day'] = df['datetime_column'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47806291",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75375599",
   "metadata": {},
   "outputs": [],
   "source": [
    "21. Feature Selection\n",
    "from pandas import read_csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# load data\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "# feature extraction\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61331a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "X = digits.images.reshape((len(digits.images), -1))\n",
    "y = digits.target\n",
    "\n",
    "# Create the RFE object and rank each pixel\n",
    "svc = SVC(kernel=\"linear\", C=1)\n",
    "rfe = RFE(estimator=svc, n_features_to_select=1, step=1)\n",
    "rfe.fit(X, y)\n",
    "ranking = rfe.ranking_.reshape(digits.images[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
